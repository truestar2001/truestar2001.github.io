<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Jinsung Yoon - CV</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <nav class="navbar">
      <ul class="nav-links">
        <li><a href="index.html" class="active">CV</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="https://mldiary.tistory.com/" target="_blank">Posts</a></li>
      </ul>
    </nav>
  </header>
<!--   <hr class="divider" /> -->
  <section class="about">
    <div class="about-container">
      <div class="about-text">
        <h1>Jinsung Yoonüé∂</h1>
        <p>
          I am a M.S. student at POSTECH, advised by Prof. Youngjoo Suh. I am interested in applying AI to acoustics and speech for various applications. 
          In particular, my focus is on speech synthesis, emotional voice conversion, and automatic music mixing. 
          As a passionate hobbyist composer, I enjoy creating music inspired by J-POP bands and actively play keyboard and synthesizer ‚Äî as well as vocals and bass. 
          My vision is to help build a world where anyone can express their inner universe through composition.
        </p>
        <div class="links">
          <a href="https://scholar.google.com/citations?hl=ko&view_op=list_works&gmla=AH8HC4yxa6-Fv_CjNbhLpUrNG6XXbUgPHAfwBXXJh-ThD8nHFj-gYRIOrSimNgdO_a047hWtct5RjFZZIW1FjBUZ8SyzS26qJ1tLgQ9PD8o62iZO33wI87lKbQ1pKVc&user=aw9Kt58AAAAJ" target="_blank" class="link-button">Google Scholar</a>
          <a href="https://mldiary.tistory.com/" target="_blank" class="link-button">Blog (AI)</a>
          <a href="https://www.linkedin.com/in/jinsung-yoon-84b5252b9/" target="_blank" class="link-button">LinkedIn</a>
          <a href="https://soundcloud.com/jinsung-yoon-956962177" target="_blank" class="link-button">Sound Cloud</a>
          <a href="https://www.instagram.com/jin_castle00/" target="_blank" class="link-button">Instagram (Music)</a>
          <a href="mailto:truestar2001@postech.ac.kr" class="link-button">Email</a>
        </div>
      </div>
      <div class="about-image">
        <img src="assets/profileimage.jpg" alt="Profile Photo">
      </div>
    </div>
  </section>

  <section id="news">
  <h2>üî• News</h2>
    <div class="news-list">
      <div class="news-item">
        <div class="news-date">Feb 2, 2026</div>
        <div class="news-content">Started working at Gaudio Lab as a research scientist, focusing on Music & Speech AI</div>
      </div>
      <div class="news-item">
        <div class="news-date">Jan 20, 2026</div>
        <div class="news-content">One paper, "AcouLetter: Enabling Fine-Grained Mid-Air Alphabetic Thumb Gesture Recognition on Smartphones with Acoustic and Inertial Sensing" has been accepted to IUI 2026</div>
      </div>
      <div class="news-item">
        <div class="news-date">Aug 6, 2025</div>
        <div class="news-content">One paper, "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody" has been accepted to ASRU 2025</div>
      </div>
      <div class="news-item">
        <div class="news-date">Jun 5, 2025</div>
        <div class="news-content">Selected as a recipient of the POSTECH Alchemist Fellowship</div>
      </div>
      <div class="news-item">
        <div class="news-date">May 20, 2025</div>
        <div class="news-content">One paper, "QR-VC: Leveraging Quantization Residuals for Linear Disentanglement in Zero-Shot Voice Conversion" has been accepted to EUSIPCO 2025</div>
      </div>
    </div>
    <hr class="news-divider" />
  </section>
  
  <section id="research">
    <h2>üéß Research Interests</h2>
    My current research focuses on audio-related deep learning applications. <br>
    Recently, I have been particularly interested in automatic arrangement and information retrieval using acoustic data.
    <ul>
      <li>Automatic Music Mixing</li>
      <li>Music Information Retrieval</li>
      <li>Speech Synthesis</li>
      <li>Emotional Voice Conversion</li>
    </ul>
  </section>

  <section id="publications">
    <h2>
      üìö Publications<br>
    </h2>

    <h3 class="subsection">Conferences & Workshops</h3>

    <p>
      <span class="paper-title">
        <strong>AcouLetter: Enabling Fine-Grained Mid-Air Alphabetic Thumb Gesture Recognition on Smartphones with Acoustic and Inertial Sensing</strong>
      </span><br>
      Su Yeon Shim, Yunho Nam, <strong>Jinsung Yoon</strong>, Wooyeol Jeong, Youngjoo Suh<br>
      <em style="color: gray;">Companion Proceedings of the 31th International Conference on Intelligent User Interfaces (IUI), 2026</em>
    </p>
    
    <p>
      <span class="paper-title">
        <strong>Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody</strong>
        <a class="paper-link-badge" href="https://arxiv.org/abs/2508.06890" target="_blank" rel="noopener">
          üîó Link
        </a>
      </span><br>
      <strong>Jinsung Yoon*</strong>, Wooyeol Jeong*, Jio Gim, Youngjoo Suh (*: equal contribution)<br>
      <em style="color: gray;">Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2025</em>
    </p>
    
    <p>
      <span class="paper-title">
        <strong>QR-VC: Leveraging Quantization Residuals for Linear Disentanglement in Zero-Shot Voice Conversion</strong>
        <a class="paper-link-badge" href="https://arxiv.org/abs/2411.16147" target="_blank" rel="noopener">
          üîó Link
        </a>
      </span><br>
      Youngjun Sim*, <strong>Jinsung Yoon*</strong>, Wooyeol Jeong, Youngjoo Suh (*: equal contribution)<br>
      <em style="color: gray;">Proceedings of the 33rd European Signal Processing Conference (EUSIPCO), 2025</em>
    </p>
    
    <h3 class="subsection">Domestic</h3>
    
    <p>
      <strong>Automatic Music Mixing Using Music Source Separation Models and Wave-U-Net</strong><br>
      <strong>Jinsung Yoon</strong>, Youngjun Sim, Youngjoo Suh<br>
      <em style="color: gray;">Proceedings of KIIT Conference, 2024</em>
    </p>
    <p>
      <strong>End-to-End One-Shot Voice Conversion Based on Vector Quantization</strong><br>
      Youngjun Sim, <strong>Jinsung Yoon</strong>, Youngjoo Suh<br>
      <em style="color: gray;">Proceedings of KICS Conference, 2024</em>
    </p>
    
  </section>
  
  <section id="education">
    <h2>üè´ Education</h2>
    <p>
      <strong>POSTECH, Pohang University of Science and Technology</strong><br>
      <em>M.S. Student in Artificial Intelligence (Advisor: Youngjoo-Suh)</em><br>
      <span class="date">Feb 2024 ‚Äì Feb 2026‚ÄÇ| Pohang, South Korea</span>
    </p>

    <p>
      <strong>Konkuk University</strong><br>
      <em>B.S. in Biotechnology (Double Major in Computer Science) </em><br>
      <span class="date">Feb 2019 ‚Äì Aug 2023‚ÄÇ|‚ÄÇSeoul, South Korea</span>
    </p>
  </section>
  
  <section id="Experiences">
    <h2>üî¨ Research Experiences</h2>
    <p>
      <strong>Gaudio Lab</strong><br>
      <em>Music Information Researcher </em><br>
      <span class="date">Feb 2026 ‚Äì Present‚ÄÇ|‚ÄÇSeoul, South Korea</span>
    </p>
    
    <p>
      <strong>POSTECH, AIoT Lab</strong><br>
      <em>Graduate Student Researcher (Advisor: Youngjoo Suh)</em><br>
      <span class="date">Feb 2024 ‚Äì Feb 2026‚ÄÇ| Pohang, South Korea</span>
    </p>
    
    <p>
      <strong>Konkuk University, HIFI AI Lab</strong><br>
      <em>Resarch Intern (Advisor: Sunghwan Kim) </em><br>
      <span class="date"> Jul 2022 ‚Äì Feb 2023‚ÄÇ|‚ÄÇSeoul, South Korea</span>
    </p>
  </section>

  <section id="projects">
    <h2>üñ•Ô∏è Projects</h2>
    <p>
      <strong>Tech Frontier Program, UC Berkeley</strong><br>
      <em>KIC Tech Frontier 25, University of California, Berkeley</em><br>
      <span class="date"> Jul 2025 ‚Äì Aug 2025</span>
    </p>
    
    <p>
      <strong>EIAM: Emotion Intensity Analysis Module</strong><br>
      <em>Square One Company</em><br>
      <span class="date"> Sep 2025 ‚Äì Dec 2025</span>
    </p>
    
    <p>
      <strong>Design of a High-Intensity Emotional Speech Synthesis System incorporating Nonverbal Vocalizations</strong><br>
      <em>Square One Company</em><br>
      <span class="date"> Feb 2025 ‚Äì Aug 2025</span>
    </p>
    
    <p>
      <strong>AI-based Music Mixing and Mastering Using Text Prompts</strong><br>
      <em>I-Corps Lab-based Startup Exploration Program</em><br>
      <span class="date"> Feb 2025 ‚Äì Dec 2025</span>
    </p>

    <p>
      <strong>Oder Complaint Automation System Using STT and NER</strong><br>
      <em>Government-funded project led by Pohang Techonopark</em><br>
      <span class="date"> Aug 2024 ‚Äì Feb 2025</span>
    </p>
  </section>

  <section id="Teaching Assistant">
    <h2>üë®‚Äçüè´ Teaching Experience</h2>
    <p>
      <strong>Research Participation (CSED399)</strong><br>
      <em>Emotional Voice Conversion Research Mentorship</em><br>
      <span class="date"> Feb 2025 ‚Äì Jun 2025</span>
    </p>
    <p>
      <strong>Programming and Problem Solving (CSED101)</strong><br>
      <em>Teaching Assistant for the lab</em><br>
      <span class="date"> Aug 2025 ‚Äì Dec 2025</span>
    </p>

  </section>
  
  <section id="musics">
    <h2>üéπ Creating Music</h2>
    <p>
      As a hobbyist composer, I enjoy creating piano-based band music using Sonar DAW, often drawing inspiration from my favorite J-POP band, Yorushika.
      I'm most comfortable with:
      <ul>
        <li>Piano</li>
        <li>Synthesizer</li>
        <li>Vocal</li>
      </ul>
      Intermediate experience in
      <ul>
        <li>Bass </li>
        <li>Acoustic Guitar </li>
        <li>DAW (Sonar)</li>
      </ul>
    </p>
    <p class="intro-text">Here are some of the songs I‚Äôve composed:</p>

    <div class="music-track">
      <p><strong>End of Spring</strong></p>
      <audio controls>
        <source src="assets/24_mix-1.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
    </div>
    
    <div class="music-track">
      <p><strong>Narke</strong></p>
      <audio controls>
        <source src="assets/12_mix.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
    </div>
    
    <div class="music-track">
      <p><strong>A Flower Falling in Spring</strong></p>
      <audio controls>
        <source src="assets/music3.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
    </div>
  
    <div class="music-track">
      <p><strong>Dream Journey</strong></p>
      <audio controls>
        <source src="assets/music1.mp3" type="audio/mp3">
        Your browser does not support the audio element.
      </audio>
    </div>

    
  </section>

  <footer>
    <p>¬© 2025 Jinsung Yoon‚ÄÇ|‚ÄÇ<a href="mailto:truestar2001@postech.ac.kr">Contact</a></p>
  </footer>
</body>
</html>
