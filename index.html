<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Your Name - Portfolio</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <nav class="navbar">
      <ul class="nav-links">
        <li><a href="index.html" class="active">CV</a></li>
        <li><a href="publications.html">Publications</a></li>
      </ul>
    </nav>
  </header>
<!--   <hr class="divider" /> -->
  <section class="about">
    <div class="about-container">
      <div class="about-text">
        <h1>Jinsung YoonðŸŽ¶</h1>
        <p>
          I am a M.S. student at POSTECH, advised by Prof. Youngjoo Suh. I am interested in applying AI to acoustics and speech for various applications. 
          In particular, my focus is on speech synthesis, emotional voice conversion, and automatic music mixing. 
          As a passionate hobbyist composer, I enjoy creating music inspired by J-POP bands and actively play keyboard and synthesizer â€” as well as vocals and bass. 
          My vision is to help build a world where anyone can express their inner universe through composition.
        </p>
        <div class="links">
          <a href="your-cv-link.pdf" target="_blank" class="link-button">CV</a>
          <a href="https://instagram.com/yourhandle" target="_blank" class="link-button">Instagram</a>
          <a href="mailto:your@email.com" class="link-button">Email</a>
        </div>
      </div>
      <div class="about-image">
        <img src="assets/profileimage.jpg" alt="Profile Photo">
      </div>
    </div>
  </section>

  <section id="research">
    <h2>Research Interests</h2>
    My current research focuses on audio-related deep learning applications. 
    Recently, I have been particularly interested in automatic arrangement and information retrieval using acoustic data.
    <ul>
      <li>Automatic Music Mixing</li>
      <li>Music Information Retrieval</li>
      <li>Speech Synthesis</li>
      <li>Emotional Voice Conversion</li>
    </ul>
  </section>

  <section id="education">
    <h2>Education</h2>
    <p>
      <strong>POSTECH, Pohang University of Science and Technology</strong><br>
      <em>M.S. Student in Artificial Intelligence (Advisor: Youngjoo-Suh)</em><br>
      <span class="date">Feb 2024 â€“ Feb 2026 (expected)â€‚| Pohang, South Korea</span>
    </p>

    <p>
      <strong>Konkuk University</strong><br>
      <em>B.S. in Computer Science (Double Major in Biotechnology) </em><br>
      <span class="date">Feb 2019 â€“ Aug 2023â€‚|â€‚Seoul, South Korea</span>
    </p>
  </section>

  <section id="publications">
    <h2>
      Publications<br>
      <small style="font-weight: normal; font-size: 0.7em; color: #888;">* Co-first author</small>
    </h2>

    <h3 class="subsection">Conferences & Workshops</h3>
    
    <p>
      <strong>Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody</strong><br>
      <strong>Jinsung Yoon*</strong>, Wooyeol Jeong*, Jio Gim, Youngjoo Suh<br>
      <em style="color: gray;">Submitted to ASRU 2025</em>
    </p>
    
    <p>
      <strong>QR-VC: Leveraging Quantization Residuals for Linear Disentanglement in Zero-Shot Voice Conversion</strong><br>
      Youngjun Sim*, <strong>Jinsung Yoon*</strong>, Wooyeol Jeong, Youngjoo Suh<br>
      <em style="color: gray;">Proceedings of the 33rd European Signal Processing Conference (EUSIPCO), 2025</em>
    </p>
    
    <h3 class="subsection">Domestic</h3>
    
    <p>
      <strong>Automatic Music Mixing Using Music Source Separation Models and Wave-U-Net</strong><br>
      <strong>Jinsung Yoon</strong>, Youngjun Sim, Youngjoo Suh<br>
      <em style="color: gray;">Proceedings of KIIT Conference, 2024</em>
    </p>
    
  </section>
  
  <section id="Experiences">
    <h2>Research Experiences</h2>
    <p>
      <strong>Square One Company</strong><br>
      <em>Graduate Student Researcher </em><br>
      <span class="date">Nov 2024 â€“ Presentâ€‚|â€‚Pohang, South Korea</span>
    </p>
    
    <p>
      <strong>POSTECH, AIoT Lab</strong><br>
      <em>Graduate Student Researcher (Advisor: Youngjoo Suh)</em><br>
      <span class="date">Feb 2024 â€“ Presentâ€‚| Pohang, South Korea</span>
    </p>
    
    <p>
      <strong>Konkuk University, HIFI AI Lab</strong><br>
      <em>Resarch Intern (Advisor: Sunghwan Kim) </em><br>
      <span class="date">Nov 2024 â€“ Presentâ€‚|â€‚Seoul, South Korea</span>
    </p>
  </section>
  
  <section id="projects">
    <h2>Projects</h2>
    <p>
      <strong>Mix-AI</strong><br>
      A deep learning model based on Wave-U-Net that performs automatic music track mixing by restoring balance across multi-channel stems.
    </p>
    <p>
      <strong>VoiceStyle</strong><br>
      Real-time voice conversion tool for expressive and stylistic speech manipulation using pitch and spectral features.
    </p>
  </section>

  <section id="musics">
    <h2>Musics</h2>
    <p>
      I also create original music using DAWs such as Cakewalk and Ableton Live. Below are some of my compositions:
    </p>
    <p>
      <a href="music1.mp3" target="_blank">[Play] Track 1 - Dreamy Synth</a><br>
      <a href="music2.mp3" target="_blank">[Play] Track 2 - Lo-fi Beat</a>
    </p>
  </section>

  <footer>
    <p>Â© 2025 Your Nameâ€‚|â€‚<a href="mailto:youremail@example.com">Contact</a></p>
  </footer>
</body>
</html>
